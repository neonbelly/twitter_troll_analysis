{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import timezone\n",
    "import string\n",
    "from string import punctuation\n",
    "from langdetect import detect\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "from xgboost import XGBClassifier\n",
    "from pytz import utc, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('modeling_df_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_cleaned'] = df['text_cleaned'].str.replace('aa', '')\n",
    "df['text_cleaned'] = df['text_cleaned'].str.replace('aaa', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = df.groupby(['user_id','is_bot']).agg({'timestamp':['min', 'max'],\n",
    "                                                    'followers':'mean',\n",
    "                                                    'following':'mean',\n",
    "                                                    'is_retweet':'sum',\n",
    "                                                    'is_quote_tweet':'sum',\n",
    "                                                    'upper_count':'sum', \n",
    "                                                    'char_count':'sum',\n",
    "                                                    'word_count':'sum', \n",
    "                                                    'hashtag_count':'sum',\n",
    "                                                    'text_cleaned': lambda x: ' '.join(x),\n",
    "                                                    'screen_name':'count'}).reset_index()\n",
    "modeling_df.columns = modeling_df.columns.droplevel(1)\n",
    "modeling_df['posts_during_period'] = modeling_df['screen_name']\n",
    "modeling_df.drop(['timestamp','screen_name'], axis = 1, inplace = True)\n",
    "modeling_df['ratio_old'] = modeling_df['followers']/(modeling_df['following']+0.0000001)\n",
    "modeling_df['ratio'] = modeling_df['ratio_old'].fillna(0)\n",
    "modeling_df.drop(['ratio_old'], axis = 1, inplace = True)\n",
    "modeling_df['ratio'] = round(modeling_df['ratio'],2)\n",
    "modeling_df['average_char'] = modeling_df['char_count']/modeling_df['posts_during_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = TfidfVectorizer(min_df = 4, max_df = .4, \n",
    "                             max_features = 35000,\n",
    "                             ngram_range = (1,2),\n",
    "                            stop_words = 'english') \n",
    "df_text = count_vect.fit_transform(modeling_df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76035, 35000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse = modeling_df.drop(['user_id','text_cleaned','is_quote_tweet'], axis = 1)\n",
    "text_features = count_vect.get_feature_names()\n",
    "number_features = list(X_sparse.columns)\n",
    "feature_names = text_features + number_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse = sparse.csr_matrix(X_sparse.values.astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76035, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = hstack((X_sparse, df_text))\n",
    "del(df_text, X_sparse)\n",
    "y = modeling_df['is_bot']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, \n",
    "                                                    test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978299467350562\n",
      "0.9558823529411765\n",
      "0.8873720136518771\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=5,random_state = 44) \n",
    "rf_model.fit(X_train, y_train)\n",
    "pred = rf_model.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(precision_score(y_test,pred))\n",
    "print(f1_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8280254777070064"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} \n",
    "for feature, importance in zip(feature_names, rf_model.feature_importances_):\n",
    "    feats[feature] = importance\n",
    "    \n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances = importances.sort_values(by='Gini-importance',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0.132785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcot tgdn</th>\n",
       "      <td>0.043439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cristiano</th>\n",
       "      <td>0.030495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isis terrorists</th>\n",
       "      <td>0.028187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jake tapper</th>\n",
       "      <td>0.027911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp let</th>\n",
       "      <td>0.027130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ultra</th>\n",
       "      <td>0.026360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kode</th>\n",
       "      <td>0.020161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wholesome</th>\n",
       "      <td>0.019869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbey</th>\n",
       "      <td>0.019045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Gini-importance\n",
       "ab                      0.132785\n",
       "tcot tgdn               0.043439\n",
       "cristiano               0.030495\n",
       "isis terrorists         0.028187\n",
       "jake tapper             0.027911\n",
       "amp let                 0.027130\n",
       "ultra                   0.026360\n",
       "kode                    0.020161\n",
       "wholesome               0.019869\n",
       "abbey                   0.019045"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3350253807106599"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "f1_score(y_test,log_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3350253807106599"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,log_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21019108280254778"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,log_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling_df.to_pickle('modeling_df_final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809768637532133"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "# X_test_counts = count_vect.transform(X_test[:,4])\n",
    "# X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "f1_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, xgb_model.predict(X_test)))\n",
    "print(recall_score(y_test, xgb_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {} \n",
    "for feature, importance in zip(feature_names, xgb_model.feature_importances_):\n",
    "    feats[feature] = importance\n",
    "    \n",
    "importances2 = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\n",
    "importances2 = importances2.sort_values(by='Gini-importance',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gini-importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0.991253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump assassinated</th>\n",
       "      <td>0.003931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbott</th>\n",
       "      <td>0.002916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab workout</th>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotes</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promo click</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promo code</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promos</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promote</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoted</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promoting</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prosecutors say</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion click</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion just</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotional</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotions</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Gini-importance\n",
       "ab                         0.991253\n",
       "trump assassinated         0.003931\n",
       "abbott                     0.002916\n",
       "ab workout                 0.001900\n",
       "word_count                 0.000000\n",
       "promotes                   0.000000\n",
       "promo                      0.000000\n",
       "promo click                0.000000\n",
       "promo code                 0.000000\n",
       "promos                     0.000000\n",
       "promote                    0.000000\n",
       "promoted                   0.000000\n",
       "promoting                  0.000000\n",
       "prosecutors say            0.000000\n",
       "promotion                  0.000000\n",
       "promotion click            0.000000\n",
       "promotion just             0.000000\n",
       "promotional                0.000000\n",
       "promotions                 0.000000\n",
       "prompt                     0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances2.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
